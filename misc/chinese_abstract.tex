	
\begin{chineseabstract}
循环神经网络是一类专门针对序列数据处理任务而设计的神经网络，广泛应用于语音识别，机器翻译和动态系统建模等领域，在时间序列相关的任务上拥有
超越其他神经网络模型的性能表现。随着任务复杂度的增长与人们对模型预测效果需求的提高，循环神经网络的模型参数量也越来越大，这对硬件
实现平台造成了巨大的存储和计算压力，也带来了高延迟等问题，阻碍了循环神经网络在更广阔场景的应用，例如嵌入式场景和IoT场景等。现有的工作分别
从模型压缩算法和硬件加速技术着手，提出了一些经典的解决方案如剪枝算法和硬件加速器，但是这些方案存在压缩成本过高，加速器专用型过强等缺陷，
无法应用在对精度和速度有动态调节需求的场景中，而这类场景又是普遍存在的。因此，开发具备精度速度动态调节能力的循环神经网络加速技术存在
很大的实用价值。

%忽视了应用场景的需求。
%因此尽管一些应用场景和需求是普遍存在的，例如具有弹性需求的场景，现有的方案由于压缩成本过高，加速器专用性过强等缺陷无法高效的完成这些工作。
针对上述问题，本文研究了循环神经网络前向前向传播过程的加速技术，基于FPGA设计并实现了具备精度和速度调节能力的循环神经网络加速系统。该系统借助基于投影的压缩算法的低成本优势，并将其和
网络的前向传播过程有机结合，实现了在系统运行过程中生成并切换到指定网络尺寸的功能，最终达成了调节系统精度速度的目的。首先，本文进行了系统架构
分析与设计，将系统的各功能组件映射到具体的软硬件实现，合理的功能划分使得系统能够高效的运转。其次，在软件算法设计上，本文考虑了系统在实际
运行过程中可能存在的突发情况，提出了基于预置投影矩阵的方法和基于状态采样的方法，这两种模型生成方法分别对应着普通应用场景和异常状态场景。
充分的应用场景考虑使得系统拥有了环境的鲁棒性。然后，在硬件实现方面，本文设计了加速循环神经网络前向传播过程的硬件加速器，
该加速器能够运行两种不同结构的网络模型并且能调节网络的尺寸，动态可调功能的硬件基础是基于分块矩阵向量乘法的计算模块。
最后，本文对系统消耗的资源进行优化，主要是使用分段三次函数近似方法优化了激活函数模块的资源消耗。系统运行效果的实验表明本文设计实现的
循环神经网络加速系统具备精度和速度的动态调节能力，加速器性能测试实验表明本文的加速器资源消耗较为合理。


%针对上述问题，本文在应用场景弹性需求的驱动以及现实资源有限的束下，以加速循环神经网络的前向传播过程为研究目标，提出了一套从算法，软件，硬件
%再到系统集成的完整解决方案。该方案通过调节网络尺寸满足了用户对模型预测精度和速度的弹性需求，通过软硬件划分实现了系统各功能组件的高效
%运转，通过定制专用硬件架构获得了网络前向传播过程计算性能的提升。首先，本文使用了基于投影方法的模型压缩算法以降低循环神经网络的模型参数量，
%包括状态近似和激活函数近似，该模型压缩算法具有压缩成本低，无需训练集以及精度损失小等优势。其次，考虑到压缩算法的低成本特性以及模型尺寸
%对网络前向传播速度的影响，本文设计了循环神经网络加速系统，该系统将网络的压缩过程和前向传播过程有机结合，
%在运行过程中可根据用户和环境对速度和精度的需求运行压缩算法生成特定尺寸的网络模型并以该尺寸模型进行前向传播。
%最后，系统的具体实现由软硬件分工协同完成。在软件方面，%根据压缩算法的数据来源不同，
%本文提出了两种压缩流程，分别是基于预置投影矩阵的方法和
%基于状态采样的方法，这两种方法对应着普通场景和异常状态场景。在硬件方面，本文设计了循环神经网络加速器，加速器主要由矩阵向量并行乘法模块和
%分段近似激活函数模块组成，并且在架构设计层面使用了模块共享和分时复用技术，有效的节省了硬件资源消耗。本文的设计基于FPGA完成实现与验证，
%实验表明本文所设计的系统能够实现模型压缩，网络模型切换和调节模型尺寸等功能，满足场景对循环神经网络前向传播速度和精度的弹性需求。



\chinesekeyword{循环神经网络，回声状态网络，硬件加速器，FPGA，高层次综合}
\end{chineseabstract}

