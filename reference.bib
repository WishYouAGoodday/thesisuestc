@article{Hornik,
  title = {Multilayer Feedforward Networks are Universal Approximators},
  author = {Kurt Hornik and Maxwell Stinchcombe and Halbert White},
  journal = {IEEE Transactions on Neural Networks},
  volume = {2},
  number = {5},
  pages = {359 -- 366},
  year = {1989}
}

@book{ComputerArchi,
  title = {Computer Architecture: A Quantitative Approach},
  author = {John Hennessy and David Patterson},
  year = {2017},
  address = {America},
  pages = {1-2},
  publisher = {Elsevier}
}


@article{Bengio1994b,
  title = {Learning long-term dependencies with gradient descent is difficult},
  author = {Y. Bengio and P. Simard and P. Frasconi},
  journal = {IEEE Transactions on Neural Networks},
  volume = {5},
  number = {2},
  pages = {157 -- 166},
  year = {1994}
}

@article{Hochreiter,
	author = {Hochreiter, Sepp},
	journal = {docter degree},
	year = {1991},
	month = {04},
	pages = {},
	title = {Untersuchungen zu dynamischen neuronalen Netzen}
}



@article{NAS_ICLR,
	author = {Zoph, Barret and Le, Quoc},
	journal = {Proc. ICLR},
	year = {2017},
	month = {4},
	pages = {1-2},
	title = {Neural Architecture Search with Reinforcement Learning}
}

@conference{NAS_CVPR,
  author={Zoph, Barret and Vasudevan, Vijay and Shlens, Jonathon and Le, Quoc V.},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={Learning Transferable Architectures for Scalable Image Recognition}, 
  year={2018},
  volume={},
  number={},
  pages={8697-8710},
  doi={10.1109/CVPR.2018.00907}
}

@article{MobileNetsV1,
  author    = {Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko and Weijun Wang},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017}
}

@conference{MobileNetsV2,
  author    = {Mark Sandler, Andrew G. Howard, Menglong Zhu and Andrey Zhmoginov and Liang Chieh Chen},
  title     = {MobileNetV2: Inverted Residuals and Linear Bottlenecks},
  booktitle = {2018 {IEEE} Conference on Computer Vision and Pattern Recognition,
               {CVPR} 2018, Salt Lake City, UT, USA, June 18-22, 2018},
  pages     = {4510--4520},
  publisher = {Computer Vision Foundation / {IEEE} Computer Society},
  year      = {2018},
  url       = {http://openaccess.thecvf.com/content\_cvpr\_2018/html/Sandler\_MobileNetV2\_Inverted\_Residuals\_CVPR\_2018\_paper.html},
  doi       = {10.1109/CVPR.2018.00474},
}
@misc{squeezenet,
	title={SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and \ensuremath{<}0.5{MB} model size},
	author={Forrest N. Iandola and Song Han and Matthew W. Moskewicz and Khalid Ashraf and William J. Dally and Kurt Keutzer},
	year={2017},
	url={https://openreview.net/forum?id=S1xh5sYgx}
}

@conference{Shuffnet,
  author={Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and Sun, Jian},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices}, 
  year={2018},
  volume={},
  number={},
  pages={6848-6856},
  doi={10.1109/CVPR.2018.00716}
}

@conference{CompRNN,
	author = {Jozefowicz, Rafal and Zaremba, Wojciech and Sutskever, Ilya},
	title = {An Empirical Exploration of Recurrent Network Architectures},
	year = {2015},
	publisher = {JMLR.org},
	booktitle = {Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37},
	pages = {2342–2350},
	location = {Lille, France},
}

@article{slstm,
	title={Sentence-State LSTM for Text Representation},
	author={Zhang, Yue and Liu, Qi and Song, Linfeng},
	booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL)}, year={2018}
}
@article{mgu,
	title = {Minimal Gated Unit for Recurrent Neural Networks},
	journal = {International Journal of Automation and Computing},
	volume = {13},
	number = {gjzdhyjszz-13-03-226},
	pages = {226},
	year = {2016},
	issn = {2731-538X},
	doi = {10.1007/s11633-016-1006-2},
	url = {https://www.mi-research.net/en/article/doi/10.1007/s11633-016-1006-2},
	author = {Guo-Bing Zhou,Jianxin Wu,Chen-Lin Zhang,Zhi-Hua Zhou}
}
@inproceedings{pruning_filters,
	title={Pruning Filters for Efficient ConvNets},
	author={Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, Hans Peter Graf},
	booktitle={International Conference on Learning Representations},
	year={2017},
	url={https://openreview.net/forum?id=rJqFGTslg}
}
@InProceedings{purning_channel,
	author = {He, Yihui and Zhang, Xiangyu and Sun, Jian},
	title = {Channel Pruning for Accelerating Very Deep Neural Networks},
	booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
	month = {Oct},
	year = {2017}
}
@inproceedings{WeightPurning,
 author = {Han, Song and Pool, Jeff and Tran, John and Dally, William},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Learning both Weights and Connections for Efficient Neural Network},
 url = {https://proceedings.neurips.cc/paper/2015/file/ae0eb3eed39d2bcef4622b2499a05fe6-Paper.pdf},
 volume = {28},
 year = {2015}
}

@ARTICLE{Purning,
  author={Karnin, E.D.},
  journal={IEEE Transactions on Neural Networks}, 
  title={A simple procedure for pruning back-propagation trained neural networks}, 
  year={1990},
  volume={1},
  number={2},
  pages={239-242},
  doi={10.1109/72.80236}
}

@inproceedings{ESE,
	author = {Han, Song and Kang, Junlong and Mao, Huizi and Hu, Yiming and Li, Xin and Li, Yubin and Xie, Dongliang and Luo, Hong and Yao, Song and Wang, Yu and Yang, Huazhong and Dally, William (Bill) J.},
	title = {ESE: Efficient Speech Recognition Engine with Sparse LSTM on FPGA},
	year = {2017},
	isbn = {9781450343541},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3020078.3021745},
	doi = {10.1145/3020078.3021745},
	booktitle = {Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
	pages = {75–84},
	location = {Monterey, California, USA},
	series = {FPGA '17}
}

@inproceedings{C-LSTM,
	author = {Wang, Shuo and Li, Zhe and Ding, Caiwen and Yuan, Bo and Qiu, Qinru and Wang, Yanzhi and Liang, Yun},
	title = {C-LSTM: Enabling Efficient LSTM Using Structured Compression Techniques on FPGAs},
	year = {2018},
	isbn = {9781450356145},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3174243.3174253},
	doi = {10.1145/3174243.3174253},
	booktitle = {Proceedings of the 2018 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
	pages = {11–20},
	location = {Monterey, CALIFORNIA, USA},
	series = {FPGA '18}
}

@inproceedings{Cao,
	author = {Cao, Shijie and Zhang, Chen and Yao, Zhuliang and Xiao, Wencong and Nie, Lanshun and Zhan, Dechen and Liu, Yunxin and Wu, Ming and Zhang, Lintao},
	title = {Efficient and Effective Sparse LSTM on FPGA with Bank-Balanced Sparsity},
	year = {2019},
	isbn = {9781450361378},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3289602.3293898},
	doi = {10.1145/3289602.3293898},
	abstract = {Neural networks based on Long Short-Term Memory (LSTM) are widely deployed in latency-sensitive language and speech applications. To speed up LSTM inference, previous research proposes weight pruning techniques to reduce computational cost. Unfortunately, irregular computation and memory accesses in unrestricted sparse LSTM limit the realizable parallelism, especially when implemented on FPGA. To address this issue, some researchers propose block-based sparsity patterns to increase the regularity of sparse weight matrices, but these approaches suffer from deteriorated prediction accuracy. This work presents Bank-Balanced Sparsity (BBS), a novel sparsity pattern that can maintain model accuracy at a high sparsity level while still enable an efficient FPGA implementation. BBS partitions each weight matrix row into banks for parallel computing, while adopts fine-grained pruning inside each bank to maintain model accuracy. We develop a 3-step software-hardware co-optimization approach to apply BBS in real FPGA hardware. First, we propose a bank-balanced pruning method to induce the BBS pattern on weight matrices. Then we introduce a decoding-free sparse matrix format, Compressed Sparse Banks (CSB), that transparently exposes inter-bank parallelism in BBS to hardware. Finally, we design an FPGA accelerator that takes advantage of BBS to eliminate irregular computation and memory accesses. Implemented on Intel Arria-10 FPGA, the BBS accelerator can achieve 750.9 GOPs on sparse LSTM networks with a batch size of 1. Compared to state-of-the-art FPGA accelerators for LSTM with different compression techniques, the BBS accelerator achieves 2.3 ~ 3.7x improvement on energy efficiency and 7.0 ~ 34.4x reduction on latency with negligible loss of model accuracy.},
	booktitle = {Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
	pages = {63–72},
	location = {Seaside, CA, USA},
	series = {FPGA '19}
}

@article{AutoMl1,
	title = {AutoPruner: An end-to-end trainable filter pruning method for efficient deep model inference},
	journal = {Pattern Recognition},
	volume = {107},
	pages = {107461},
	year = {2020},
	issn = {0031-3203},
	doi = {https://doi.org/10.1016/j.patcog.2020.107461},
	url = {https://www.sciencedirect.com/science/article/pii/S0031320320302648},
	author = {Jian-Hao Luo and Jianxin Wu}
}

@inproceedings{AutoMl2,
	author = {He, Yihui and Lin, Ji and Liu, Zhijian and Wang, Hanrui and Li, Li-Jia and Han, Song},
	title = {AMC: AutoML for Model Compression and Acceleration on Mobile Devices},
	year = {2018},
	isbn = {978-3-030-01233-5},
	publisher = {Springer-Verlag},
	address = {Berlin, Heidelberg},
	url = {https://doi.org/10.1007/978-3-030-01234-2_48},
	doi = {10.1007/978-3-030-01234-2_48},
	booktitle = {Computer Vision – ECCV 2018: 15th European Conference, Munich, Germany, September 8–14, 2018, Proceedings, Part VII},
	pages = {815–832},
	location = {Munich, Germany}
}
@InProceedings{LQ-nets,
	author = {Zhang, Dongqing and Yang, Jiaolong and Ye, Dongqiangzi and Hua, Gang},
	title = {LQ-Nets: Learned Quantization for Highly Accurate and Compact Deep Neural Networks},
	booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
	month = {September},
	year = {2018}
}
@article{DoReFa,
  author    = {Shuchang Zhou and
               Zekun Ni and
               Xinyu Zhou and
               He Wen and
               Yuxin Wu and
               Yuheng Zou},
  title     = {DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with
               Low Bitwidth Gradients},
  journal   = {CoRR},
  volume    = {abs/1606.06160},
  year      = {2016},
  url       = {http://arxiv.org/abs/1606.06160},
  eprinttype = {arXiv},
  eprint    = {1606.06160}
}
@inproceedings{ABC-net,
	 author = {Lin, Xiaofan and Zhao, Cong and Pan, Wei},
	 booktitle = {Advances in Neural Information Processing Systems},
	 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	 pages = {},
	 publisher = {Curran Associates, Inc.},
	 title = {Towards Accurate Binary Convolutional Neural Network},
	 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/b1a59b315fc9a3002ce38bbe070ec3f5-Paper.pdf},
	 volume = {30},
	 year = {2017}
}
@article{INQ,
 	 title={Incremental Network Quantization: Towards Lossless CNNs with Low-Precision Weights},
 	 author={Aojun Zhou and Anbang Yao and Yiwen Guo and Lin Xu and Yurong Chen},
 	 journal={ArXiv},
 	 year={2017},
 	 volume={abs/1702.03044}
}
@inproceedings{BNN,
 	author = {Hubara, Itay and Courbariaux, Matthieu and Soudry, Daniel and El-Yaniv, Ran and Bengio, Yoshua},
 	booktitle = {Advances in Neural Information Processing Systems},
	 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
	 pages = {},
	 publisher = {Curran Associates, Inc.},
	 title = {Binarized Neural Networks},
	 url = {https://proceedings.neurips.cc/paper_files/paper/2016/file/d8330f857a17c53d217014ee776bfd50-Paper.pdf},
	 volume = {29},
	 year = {2016}
}
@inproceedings{XNOR-net,
    Author = {Mohammad Rastegari and Vicente Ordonez and Joseph Redmon and Ali Farhadi},
    Title = {XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks},
    Booktitle = {ECCV},
    Year = {2016}
}
@inproceedings{TBN,
  title={TBN: Convolutional Neural Network with Ternary Inputs and Binary Weights},
  author={Diwen Wan and Fumin Shen and Li Liu and Fan Zhu and Jie Qin and Ling Shao and Heng Tao Shen},
  booktitle={European Conference on Computer Vision},
  year={2018}
}

@article{TWN,
  author    = {Fengfu Li and
               Bin Liu},
  title     = {Ternary Weight Networks},
  journal   = {CoRR},
  volume    = {abs/1605.04711},
  year      = {2016},
  url       = {http://arxiv.org/abs/1605.04711},
  eprinttype = {arXiv},
  eprint    = {1605.04711}
}

@article{FP-BNN,
	title = {FP-BNN: Binarized neural network on FPGA},
	journal = {Neurocomputing},
	volume = {275},
	pages = {1072-1086},
	year = {2018},
	issn = {0925-2312},
	doi = {https://doi.org/10.1016/j.neucom.2017.09.046},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231217315655},
	author = {Shuang Liang and Shouyi Yin and Leibo Liu and Wayne Luk and Shaojun Wei}
}

@inproceedings{lowrank,
	 author = {Indyk, Piotr and Vakilian, Ali and Yuan, Yang},
 	booktitle = {Advances in Neural Information Processing Systems},
 	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 	pages = {},
 	publisher = {Curran Associates, Inc.},
 	title = {Learning-Based Low-Rank Approximations},
 	url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/1625abb8e458a79765c62009235e9d5b-Paper.pdf},
 	volume = {32},
 	year = {2019}
}
@InProceedings{SVD,
	author={Bermeitinger, Bernhard and Hrycej, Tomas and Handschuh, Siegfried},
	title={Singular Value Decomposition and Neural Networks},
	booktitle={rtificial Neural Networks and Machine Learning -- ICANN 2019: Deep Learning},
	year={2019},
	publisher={Springer International Publishing},
	pages={153--164},
}

@article{TensorTrain,
	author = {Oseledets, I. V.},
	title = {Tensor-Train Decomposition},
	journal = {SIAM Journal on Scientific Computing},
	volume = {33},
	number = {5},
	pages = {2295-2317},
	year = {2011},
	doi = {10.1137/090752286},
}
@INPROCEEDINGS{CP,
  author={Ma, Ruixin and Wang, Chuang and Li, Xin},
  booktitle={2021 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)}, 
  title={CP Decomposition for Fast training of Bi-LSTM}, 
  year={2021},
  volume={},
  number={},
  pages={244-248},
  doi={10.1109/DASC-PICom-CBDCom-CyberSciTech52372.2021.00051}}

@InProceedings{BT,
	author = {Ye, Jinmian and Wang, Linnan and Li, Guangxi and Chen, Di and Zhe, Shandian and Chu, Xinqi and Xu, Zenglin},
	title = {Learning Compact Recurrent Neural Networks With Block-Term Tensor Decomposition},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2018}
}

@InProceedings{QuantCVPR,
	author = {Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
	title = {Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2018}
}

@inproceedings{HitNet,
 	author = {Wang, Peiqi and Xie, Xinfeng and Deng, Lei and Li, Guoqi and Wang, Dongsheng and Xie, Yuan},
 	booktitle = {Advances in Neural Information Processing Systems},
 	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 	pages = {},
	publisher = {Curran Associates, Inc.},
 	title = {HitNet: Hybrid Ternary Recurrent Neural Network},
 	url = {https://proceedings.neurips.cc/paper/2018/file/82cec96096d4281b7c95cd7e74623496-Paper.pdf},
 	volume = {31},
 	year = {2018}
}

@inproceedings{TernaryQuanti,
	title={Trained Ternary Quantization},
	author={Chenzhuo Zhu and Song Han and Huizi Mao and William J. Dally},
	booktitle={International Conference on Learning Representations},
	year={2017},
	url={https://openreview.net/forum?id=S1_pAu9xl}
}

@ARTICLE{E-LSTM,
  author={Wang, Meiqi and Wang, Zhisheng and Lu, Jinming and Lin, Jun and Wang, Zhongfeng},
  journal={IEEE Journal on Emerging and Selected Topics in Circuits and Systems}, 
  title={E-LSTM: An Efficient Hardware Architecture for Long Short-Term Memory}, 
  year={2019},
  volume={9},
  number={2},
  pages={280-291},
  doi={10.1109/JETCAS.2019.2911739}
}

@article{Lacey,
  title={Deep Learning on FPGAs: Past, Present, and Future},
  author={Griffin Lacey and Graham W. Taylor and Shawki Areibi},
  journal={ArXiv},
  year={2016},
  volume={abs/1602.04283}
}

@article{DeepRnn,
  title={Hardware accelerators for recurrent neural networks on FPGA},
  author={Andre Xian Ming Chang and Eugenio Culurciello},
  journal={2017 IEEE International Symposium on Circuits and Systems (ISCAS)},
  year={2017},
  pages={1-4}
}

@ARTICLE{WangLong:TNNLS'23,
	author = {Hai Wang and Xingyi Long and Xue-Xin Liu},
	journal = tnnls,
	title = {{fastESN}: Fast Echo State Network},
	year = {2022},
        OPTmonth = {October},
        OPTvolume = {70},
        OPTnumber = {10},
        OPTpages = {1539--1554},
}

@article{wang1999sanwei,
  title = {三维矢量散射积分方程中奇异性分析},
  author = {王浩刚 and 聂在平},
  journal = {电子学报},
  volume = {27},
  number = {12},
  pages = {68 -- 71},
  year = {1999}
}

@conference{liuxf2006,
  author = {Liu, X F and Wang, Bing Zhong and Shao, Wei and Wen Wang},
  title = {A marching-on-in-order scheme for exact attenuation constant extraction of lossy transmission lines},
  year = {2006},
  pages = {527-529},
  address = {Chengdu},
  booktitle = {China-Japan Joint Microwave Conference Proceedings}
}

@inproceedings{AlexNet,
 	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 	booktitle = {Advances in Neural Information Processing Systems},
 	editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 	pages = {},
 	publisher = {Curran Associates, Inc.},
 	title = {ImageNet Classification with Deep Convolutional Neural Networks},
 	url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 	volume = {25},
 	year = {2012}
}
@article{Cudnn,
  author    = {Sharan Chetlur and
               Cliff Woolley and
               Philippe Vandermersch and
               Jonathan Cohen and
               John Tran and
               Bryan Catanzaro and
               Evan Shelhamer},
  title     = {cuDNN: Efficient Primitives for Deep Learning},
  journal   = {CoRR},
  volume    = {abs/1410.0759},
  year      = {2014},
  url       = {http://arxiv.org/abs/1410.0759},
  eprinttype = {arXiv},
  eprint    = {1410.0759}
}

@book{zhu1973wulixue,
  title = {物理学},
  author = {竺可桢},
  year = {1973},
  address = {北京},
  pages = {56-60},
  publisher = {科学出版社}
}

@thesis{chen2001hao,
  author = {陈念永},
  title = {毫米波细胞生物效应及抗肿瘤研究},
  institution = {电子科技大学},
  year = {2001},
  pages = {50-60},
  address = {成都}
}

@newspaper{gu2012lao,
  author = {顾春},
  title = {牢牢把握稳中求进的总基调},
  journal = {人民日报},
  date = {2012年3月31日}
}

@techreport{feng997he,
  author = {冯西桥},
  title = {核反应堆压力容器的{LBB}分析},
  institution = {清华大学核能技术设计研究院},
  date = {1997年6月25日},
  address = {北京}
}

@patent{xiao2012yi,
  author = {肖珍新},
  title = {一种新型排渣阀调节降温装置},
  date = {2012年4月25日},
  type = {实用新型专利},
  country = {中国},
  id = {ZL201120085830.0}
}

@standard{zhong1994zhong,
  institution = {中华人民共和国国家技术监督局},
  id = {GB3100-3102},
  title = {中华人民共和国国家标准--量与单位},
  publisher = {中国标准出版社},
  date = {1994年11月1日},
  address = {北京}
}

@digital{clerc2010discrete,
  author = {M. Clerc},
  title = {Discrete particle swarm optimization: a fuzzy combinatorial box},
  type = {EB/OL},
  date = {July 16, 2010},
  url = {http://clere.maurice.free.fr/pso/Fuzzy_Discrere_PSO/Fuzzy_DPSO.htm}
}
