\chapter{循环神经网络加速技术基础}

\section{循环神经网络及其变体}
循环神经网络是一种专门针对序列数据进行建模的神经网络模型。有别于前馈神经网络，卷积神经网络等“静态模型”，循环神经网络在结构上拥有循环
自连接的反馈机制，这使得模型当前的输出不仅取决于当前输入，还与当前的状态有关。通过对状态的存储与更新，循环神经网络能够有效的建模动态系统。
理论上，任何图灵可计算的函数都可以用有限维的循环网络近似。尽管循环神经网络功能强大，但是高昂的训练成本阻碍了循环神经网络的实际应用。
一方面，固定有序的前向传播过程只能遵循序列顺序先后计算，因此通过时间的反向传播无法并行计算；另一方面，梯度消失和梯度爆炸问题在循环神经网络
的训练过程中尤为突出，这导致其学习长期依赖关系变的困难。随着理论研究的发展和算力的提升，以上问题都得以解决。借助第三次人工智能浪潮
循环神经网络重新焕发出勃勃生机，目前，循环神经网络已经广泛应用于自然语言处理等相关领域。

\subsection{普通循环神经网络}
普通循环神经网络是最简单的循环神经网络结构，主要包括输入层，隐藏层和输出层。输入层对输入进行特征提取并映射为固定长度的向量，隐藏层将输入信息
和前一时刻的状态转化为新的状态，输出层根据网络存储的状态解码并完成输出。其中隐藏层包含记忆信息以及记忆更新的规则，是循环神经网络中最重要的
结构。
常见的循环神经网络结构如图\ref{fig:rnn}所示，权重矩阵\(U, W, V\)分别表示输入到到隐藏，隐藏到隐藏，隐藏到输出之间的连接，向量\(x, h, o\)分别表示输入单元，
隐藏单元和输出单元，这些单元及其相互连接形成网络。相比于其他网络模型的单向信息传递，循环神经网络引入环状结构实现了从输入到输出的双向信息
流动。一些符合训练准则的信息将会通过循环的方式长期保存在网络状态中，并根据输入序列特征进行适时唤醒记忆。当网络记忆的信息足够丰富时，循环神经
网络不仅能准确的预测输出，并且能大致恢复输入序列。自编码器框架就是基于此原理而产生，其能根据记忆的状态信息选择重要的输入并近似复制到输出，
实现特征学习或降维。图中左侧为循环神经网络回路原理图，黑色方块表示回路中单个时间步的延迟，即时刻t-1的状态会影响时刻t的状态。图中右侧为
循环神经网络按时间展开的计算图，展开是指将左侧的回路结构映射为右侧的包含重复组件的结构，展开的深度取决与序列的长度。循环神经网络展开结构图
显式的数据流动路径描述了信息是如何在时间上向前和向后传递的。
\begin{figure}
	\centering
	\includegraphics[width=0.8\columnwidth]{RNN_struct.eps}
	\caption{循化神经网络结构图}
	\label{fig:rnn}
\end{figure}

循环神经网络的数学模型为式\ref{eq:rnn}，

\begin{equation}\label{eq:rnn}
	\begin{split}
		h_{t} &= g(W*h_{t-1} + U*x_{t})	\\
		y_{t} &= f(V*h_{t})						
	\end{split}
\end{equation}





\begin{align*}
&i_t = \sigma(W_{ix}*x_t + W_{ir}*y_{t-1} + W_{ic}*c_{t-1} +b_i)	\\
&f_t = \sigma(W_{fx}*x_t + W_{fr}*y_{t-1} + W_{fc}*c_{t-1} +b_f)	\\
&g_t = \sigma(W_{cx}*x_t + W_{cr}*y_{t-1} + b_c)					\\
&c_t = f_t \odot c_{t-1} + g_t \odot i_t							\\
&o_t = \sigma(W_{ox*x_{t} + W_{or} \*y_{t-1} + W_{oc}*c_t} + b_o)	\\
&m_t = o_t \odot h_{c_t}											\\
&y_t = W_{ym}*m_t													\label{eq:Maxwell}
\end{align*}










\subsection{长短期记忆神经网络}
\subsection{回声状态网络} 

\section{模型压缩与加速算法}
RWG 基函数是定义在三角形单元上的最具代表性的基函数。它的具体定义如下：
\begin{equation}
f_n(\bm{r})=
\begin{cases}
\frac{l_n}{2A_n^+}\bm{\rho}_n^+=\frac{l_n}{2A_n^+}(\bm{r}-\bm{r}_+)&\bm{r}\in T_n^+\\
\frac{l_n}{2A_n^-}\bm{\rho}_n^-=\frac{l_n}{2A_n^-}(\bm{r}_--\bm{r})&\bm{r}\in T_n^-\\
0&\text{otherwise}
\end{cases}
\end{equation}

其中，$l_n$为三角形单元$T_n^+$和$T_n^-$公共边的长度，$A_n^+$和$A_n^-$分别为三角形单元$T_n^+$和$T_n^-$的面积（如图\ref{pica}所示）。

\begin{figure}[h]
	\includegraphics{pica.pdf}
	\caption{RWG 基函数几何参数示意图}
	\label{pica}
\end{figure}

由于时域混合场积分方程是时域电场积分方程与时域磁场积分方程的线性组合，因此时域混合场积分方程时间步进算法的阻抗矩阵特征与时域电场积分方程时间步进算法的阻抗矩阵特征相同。
\begin{equation}
\label{latent_binary_variable}
\bm{r}_{i,j}=
\begin{cases}
1,f(\bm{x}^{i};\bm{w})\cdot f(\bm{x}^{j};\bm{w})\geq u(\lambda),\\
0,f(\bm{x}^{i};\bm{w})\cdot f(\bm{x}^{j};\bm{w})< l(\lambda), 1\leq i,j\leq n.\\
f(\bm{x}^{i};\bm{w})\cdot f(\bm{x}^{j};\bm{w}),\text{otherwise},
\end{cases}
\end{equation}

时域积分方程时间步进算法的阻抗元素直接影响算法的后时稳定性，因此阻抗元素的计算是算法的关键之一，采用精度高效的方法计算时域阻抗元素是时域积分方程时间步进算法研究的重点之一。


\subsection{轻量化网络}

\subsection{模型稀疏化}

\subsection{数值量化}

\subsection{张量分解}

\section{硬件加速平台介绍}

\subsection{FPGA硬件加速技术}

\subsection{开发工具}


如图\ref{picb}和图\ref{picc}所示分别给出了参数$E_0=\hat{x}$，$a_n=-\hat{z}$，$f_0=250MHz$，$f_w=50MHz$，$t_w=4.2\sigma$时，调制高斯脉冲的时域与频域归一化波形图。

\begin{figure}[h]
\subfloat[]{
	\label{picb}
	\includegraphics[width=7.3cm]{picb.pdf}
}
\subfloat[]{
	\label{picc}
	\includegraphics[width=6.41cm]{picc.pdf}
}
\caption{调制高斯脉冲时域与频率波形，时域阻抗元素的存储技术也是时间步进算法并行化的关键技术之一。(a)调制高斯脉冲信号的时域波形；(b)调制高斯脉冲信号的频域波形}
\label{fig1}
\end{figure}

时域阻抗元素的存储技术\citing{xiao2012yi}也是时间步进算法并行化的关键技术之一，采用合适的阻抗元素存储方式可以很大的提高并行时间步进算法的计算效率。

\section{本章小结}
本章首先从时域麦克斯韦方程组出发推导得到了时域电场、磁场以及混合场积分方程。

